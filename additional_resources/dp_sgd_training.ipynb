{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy DP-SGD Script\n",
    "\n",
    "This script incorporates a epsilon threashold into the training loop as a callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy_lib\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasSGDOptimizer\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasAdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_entries(path):\n",
    "    data_dir = Path(\"/project/differential-privacy/adult_analysis/\")\n",
    "    df = pd.read_csv(data_dir / path)\n",
    "    return df.drop(np.random.choice(df.index, (df.shape[0]%100), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training, test and validation datasets\n",
    "train_df = remove_random_entries(\"data/train-one-hot.csv\")\n",
    "train_target_df = train_df.pop('salary')\n",
    "\n",
    "test_df = remove_random_entries(\"data/test-one-hot.csv\")\n",
    "test_target_df = test_df.pop('salary')\n",
    "\n",
    "val_df = remove_random_entries(\"data/val-one-hot.csv\")\n",
    "val_target_df = val_df.pop('salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "NUM_TRAIN_EXAMPLES=len(train_target_df.values)\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=100\n",
    "N_MICROBATCHES=100\n",
    "LEARNING_RATE=0.001\n",
    "L2_NORM_CLIP=2\n",
    "NOISE_MULTIPLIER=2\n",
    "DELTA=1e-5\n",
    "\n",
    "if BATCH_SIZE % N_MICROBATCHES != 0:\n",
    "    raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method which takes in steps and returns privacy spent in steps taken\n",
    "# > NOISE_MULTIPLIER\n",
    "# > BATCH_SIZE\n",
    "# > DELTA\n",
    "def compute_epsilon(steps, batch_size=BATCH_SIZE, num_training_examples=NUM_TRAIN_EXAMPLES, noise_multiplier=NOISE_MULTIPLIER):\n",
    "    \"\"\"Computes epsilon value for given hyperparameters.\"\"\"\n",
    "    if NOISE_MULTIPLIER == 0.0:\n",
    "        return float('inf')\n",
    "    orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
    "    sampling_probability = batch_size / num_training_examples\n",
    "    rdp = compute_rdp(q=sampling_probability,\n",
    "                    noise_multiplier=NOISE_MULTIPLIER,\n",
    "                    steps=steps,\n",
    "                    orders=orders)\n",
    "    # Delta is set to approximate 1 / (number of training points).\n",
    "    return get_privacy_spent(orders, rdp, target_delta=DELTA)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon_per_epoch(total_epochs):\n",
    "    epsilon_epoch = [[] for _ in range(2)]\n",
    "    for epoch in range(total_epochs):\n",
    "        steps = epoch*len(train_target_df.values)/BATCH_SIZE\n",
    "        epsilon_epoch[0].append(epoch)\n",
    "        epsilon_epoch[1].append(compute_epsilon(steps))\n",
    "    return pd.DataFrame({'epochs': epsilon_epoch[0], 'epsilon': epsilon_epoch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(63,)))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    \n",
    "    optimizer = DPKerasSGDOptimizer(\n",
    "        l2_norm_clip=L2_NORM_CLIP,\n",
    "        noise_multiplier=NOISE_MULTIPLIER,\n",
    "        num_microbatches=N_MICROBATCHES,\n",
    "        learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE),\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon(epoch):\n",
    "    steps = (epoch + 1) * NUM_TRAIN_EXAMPLES / BATCH_SIZE\n",
    "    epsilon=compute_epsilon(steps)\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        eps = get_epsilon(epoch)\n",
    "        print(f\"Epoch: {epoch}, epsilon: {eps:.5f}\")\n",
    "        if eps < self.threshold:\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.model.stop_training = True\n",
    "            # revert to final valid epoch\n",
    "            self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(\n",
    "    train_df.values,\n",
    "    train_target_df.values,\n",
    "    validation_data=(val_df.values, val_target_df.values),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS, \n",
    "    verbose=1,\n",
    "    callbacks=[CustomCallback(threshold=0.3), tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10)],\n",
    ")\n",
    "end = time.time()\n",
    "print(\"Total time:\", datetime.timedelta(seconds=end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Summary of the model performance. The defined methods can be used to compare multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model plotter\n",
    "def plot_model_results(history, clr, i=\"_alt\"):\n",
    "    ax[0].plot(history.history[\"loss\"], \"{}\".format(clr), label=\"M{} Train loss\".format(i), linewidth=2)\n",
    "    ax[0].plot(history.history[\"val_loss\"], \"{}--\".format(clr), label=\"M{} Val loss\".format(i), linewidth=2)\n",
    "    ax[1].plot(history.history[\"accuracy\"], \"{}\".format(clr), label=\"M{} Train accuracy\".format(i), linewidth=1.5)\n",
    "    ax[1].plot(history.history[\"val_accuracy\"], \"{}--\".format(clr), label=\"M{} Val accuracy\".format(i), linewidth=1.5)\n",
    "    ax[0].set_xlabel(\"$Epochs$\", fontsize=16), ax[1].set_xlabel(\"$Epochs$\", fontsize=16)\n",
    "    ax[0].set_ylabel(\"$Loss$\", fontsize=16), ax[1].set_ylabel(\"$Accuracy$\", fontsize=16)\n",
    "    ax[0].set_title(\"Loss\", fontsize=18), ax[1].set_title(\"Accuracy\", fontsize=18)\n",
    "    ax[0].legend(frameon=False, fontsize=14), ax[1].legend(frameon=False, fontsize=14)\n",
    "    \n",
    "# print results\n",
    "def return_results(model, test_features, test_labels, i=\"0\"):\n",
    "    # Evaluate model comparison\n",
    "    loss, acc = model.evaluate(test_features, test_labels, verbose=0)\n",
    "    print(\"M{}|| Accuracy: {:.2f}% --- Loss: {:.2f}\".format(i, 100 * acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result summary \n",
    "return_results(model, test_df.values, test_target_df.values)\n",
    "\n",
    "# create a loss & accuracy subplot\n",
    "f, ax = plt.subplots(figsize=(14, 6), ncols=2)\n",
    "\n",
    "# plot results of each model\n",
    "plot_model_results(history, \"g\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
