{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult dataset preprocessing\n",
    "This notebook is to preprocess the [Adult dataset](https://archive.ics.uci.edu/ml/datasets/Adult)\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"salary\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    \"\"\"\n",
    "    Helper function that strips leading / trailing whitespace, lower\n",
    "    cases, and replaces hyphens with underscores.\n",
    "    \"\"\"\n",
    "    return s.strip().lower().replace(\"-\", \"_\")\n",
    "\n",
    "\n",
    "def parse_native_country(country):\n",
    "    \"\"\"\n",
    "    Group countries other than United-States and Mexico into single\n",
    "    \"other\" category\"\n",
    "    \"\"\"\n",
    "    country = clean_string(country)\n",
    "    if country == \"united_states\" or country == \"mexico\":\n",
    "        return country\n",
    "    return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        header=None,\n",
    "        na_values=[\" ?\"],\n",
    "        names=names,\n",
    "    )\n",
    "    .drop(columns=[\"fnlwgt\", \"education_num\"])\n",
    "    # drop all rows with missing values\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    # simple preprocessing on columns\n",
    "    .assign(\n",
    "        # clean all string columns\n",
    "        education=lambda df: df.education.map(clean_string),\n",
    "        marital_status=lambda df: df.marital_status.map(clean_string),\n",
    "        occupation=lambda df: df.occupation.map(clean_string),\n",
    "        race=lambda df: df.race.map(clean_string),\n",
    "        relationship=lambda df: df.relationship.map(clean_string),\n",
    "        workclass=lambda df: df.workclass.map(clean_string),\n",
    "        # clean and aggregate native_country\n",
    "        native_country=lambda df: df.native_country.map(parse_native_country),\n",
    "        # encode binary features as integers\n",
    "        salary=lambda df: (df.salary == \" >50K\").astype(np.int32),\n",
    "        sex=lambda df: (df.sex == \" Male\").astype(np.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (\n",
    "    pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "        header=None,\n",
    "        na_values=[\" ?\"],\n",
    "        skiprows=1,\n",
    "        names=names,\n",
    "    )\n",
    "    .drop(columns=[\"fnlwgt\", \"education_num\"])\n",
    "    # drop all rows with missing values\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    # simple preprocessing on columns\n",
    "    .assign(\n",
    "        # clean all string columns\n",
    "        education=lambda df: df.education.map(clean_string),\n",
    "        marital_status=lambda df: df.marital_status.map(clean_string),\n",
    "        occupation=lambda df: df.occupation.map(clean_string),\n",
    "        race=lambda df: df.race.map(clean_string),\n",
    "        relationship=lambda df: df.relationship.map(clean_string),\n",
    "        workclass=lambda df: df.workclass.map(clean_string),\n",
    "        # clean and aggregate native_country\n",
    "        native_country=lambda df: df.native_country.map(parse_native_country),\n",
    "        # encode binary features as integers\n",
    "        # note extra '.' in test set not present in train set\n",
    "        salary=lambda df: (df.salary == \" >50K.\").astype(np.int32),\n",
    "        sex=lambda df: (df.sex == \" Male\").astype(np.int32),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(train.education) == set(test.education)\n",
    "assert set(train.race) == set(test.race)\n",
    "assert set(train.relationship) == set(test.relationship)\n",
    "assert set(train.marital_status) == set(test.marital_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"occupation\",\n",
    "    \"race\",\n",
    "    \"relationship\",\n",
    "    \"marital_status\",\n",
    "    \"native_country\",\n",
    "]\n",
    "\n",
    "cts_features = [\"age\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "\n",
    "binary_features = [\"sex\", \"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white                 25933\n",
       "black                  2817\n",
       "asian_pac_islander      895\n",
       "amer_indian_eskimo      286\n",
       "other                   231\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(\n",
    "    [train, pd.get_dummies(train.loc[:, one_hot_features], dtype=np.int32)],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "test_df = pd.concat(\n",
    "    [test, pd.get_dummies(test.loc[:, one_hot_features], dtype=np.int32)],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_df.columns.tolist() == test_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data_dir = Path(\"/project/differential-privacy/adult_analysis/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = cts_features + one_hot_features + binary_features\n",
    "\n",
    "train_df[original_features].to_csv(\n",
    "    adult_data_dir / \"train.csv\", index=False\n",
    ")\n",
    "val_df[original_features].to_csv(\n",
    "    adult_data_dir / \"val.csv\", index=False\n",
    ")\n",
    "test_df[original_features].to_csv(\n",
    "    adult_data_dir / \"test.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "train_df[cts_features] = ss.fit_transform(train_df[cts_features])\n",
    "val_df[cts_features] = ss.transform(val_df[cts_features])\n",
    "test_df[cts_features] = ss.transform(test_df[cts_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=one_hot_features).to_csv(\n",
    "    adult_data_dir / \"train-one-hot.csv\", index=False\n",
    ")\n",
    "val_df.drop(columns=one_hot_features).to_csv(\n",
    "    adult_data_dir / \"val-one-hot.csv\", index=False\n",
    ")\n",
    "test_df.drop(columns=one_hot_features).to_csv(\n",
    "    adult_data_dir / \"test-one-hot.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
