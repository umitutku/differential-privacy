{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Dataset Analysis\n",
    "\n",
    "This notebook uses the self-influence results generated by **adult_training.ipynb** to perform analysis and investigate the nature of self-influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Results\n",
    "Models are loaded from pickle files. First entry in the file is always teh averaged self-influence score. A list of models used is created to refer to the specific model in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cps = [0, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, -1]\n",
    "\n",
    "# List of dictionaries: Average CP, CP 1, CP 2, CP 3, CP 5, CP 10, CP 50\n",
    "with open('results/scan_results_shuffled_500.pickle', 'rb') as handle:\n",
    "    scan_results = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method defined to apply cuts on self-influence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_with_cut(results, min_infl = 0, max_infl=1000):\n",
    "    processed_results = []\n",
    "    for result in results:\n",
    "        X = [i for i in result.get(\"memorisation\") if i > min_infl and i < max_infl]\n",
    "        processed_results.append(X)\n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting influence distributions and boxplots of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result histograms\n",
    "MIN = 1\n",
    "MAX = 400\n",
    "\n",
    "processed_results = results_with_cut(scan_results, MIN, MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot options\n",
    "BINS = 100\n",
    "ALPHA = 0.3\n",
    "X_MAX = MAX\n",
    "EPOCH_INDEX = model_cps.index(50)\n",
    "\n",
    "# influence distribution\n",
    "f, ax = plt.subplots(figsize=(10, 5), ncols=1)\n",
    "\n",
    "ax.hist(processed_results[EPOCH_INDEX], bins=BINS, histtype=u'step', linewidth=2, label='Epoch 50')\n",
    "ax.hist(processed_results[-1], bins=BINS, histtype=u'step', linewidth=2, label='Ave. Checkpoint')\n",
    "    \n",
    "ax.legend(frameon=False, fontsize=12)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim([0, X_MAX])\n",
    "ax.set_title(\"Self-influence distribution for training dataset\", fontsize=14)\n",
    "#ax.set(xlabel=\"Self Influence Score\", ylabel=\"Counts\")\n",
    "plt.xlabel(\"Self Influence Score\", fontsize=12)\n",
    "plt.ylabel(\"Counts\", fontsize=12)\n",
    "\n",
    "plt.savefig(\"plots/self_influence_two_distributions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot options\n",
    "BINS = 100\n",
    "ALPHA = 0.3\n",
    "EPOCH = 50\n",
    "X_MAX = MAX\n",
    "EPOCH_INDEX = model_cps.index(EPOCH)\n",
    "\n",
    "# influence distribution\n",
    "f, ax = plt.subplots(figsize=(10, 5), ncols=1)\n",
    "for i in range(len(processed_results)):\n",
    "    LABEL = \"Ave. CP\" if model_cps[i]==-1 else\"Epoch {}\".format(model_cps[i]) \n",
    "    ax.hist(processed_results[i], bins=BINS, histtype=u'step', linewidth=2, label=LABEL)\n",
    "    \n",
    "ax.legend(frameon=False, fontsize=12)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim([0, X_MAX])\n",
    "ax.set_title(\"Self-influence distribution for training dataset\", fontsize=14)\n",
    "#ax.set(xlabel=\"Self Influence Score\", ylabel=\"Counts\")\n",
    "\n",
    "plt.xlabel(\"Self Influence Score\", fontsize=12)\n",
    "plt.ylabel(\"Counts\", fontsize=12)\n",
    "\n",
    "plt.savefig(\"plots/self_influence_adult.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot options\n",
    "boxprops = dict(linestyle='-', linewidth=2, color='black')\n",
    "flierprops = dict(marker='o', markerfacecolor='white', markersize=10,\n",
    "                  linestyle='none')\n",
    "medianprops = dict(linestyle='-', linewidth=2, color='firebrick')\n",
    "\n",
    "# create box plots for different CPs \n",
    "f_1, ax_1 = plt.subplots(figsize=(8, 5), ncols=1)\n",
    "\n",
    "LABELS = []\n",
    "for i in range(len(processed_results)):\n",
    "    label = \"Ave. CP\" if model_cps[i]==-1 else\"CP-{}\".format(model_cps[i-1])\n",
    "    LABELS.append(label)\n",
    "    \n",
    "ax_1.set_xticklabels(LABELS, fontdict=None, minor=False)\n",
    "ax_1.set_xlabel(\"Checkpoint Snapshots\", fontsize=12)\n",
    "ax_1.set_ylabel(\"Self-Influence Score\", fontsize=12)\n",
    "\n",
    "\n",
    "ax_1.boxplot(processed_results, widths=0.9, medianprops=medianprops, boxprops=boxprops, flierprops=flierprops)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying the evolution of individual influence examples across training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method which returns an example index that lies between the desired minimum and maximum selected percentile influence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_example_index(p_start, p_width, reduced_width, m):\n",
    "    \"\"\"\n",
    "    This function returns the index of a random example between a desired percentile range.\n",
    "    - p_start is used to determine the lowest index \n",
    "    - p_width represents the width of the percentile\n",
    "    - reduced_width is used to select a smaller region within width of percentile\n",
    "      to return examples closer to the median representation\n",
    "    - e.g. p_start = 0.2 and p_width = 0.2 will return a random example between the 20th-40th percentile \n",
    "    \"\"\"\n",
    "    if p_start and p_width > 1:\n",
    "        print (\"Set percentile and width between 0-1.\")\n",
    "    else:\n",
    "        n = len(m) # length of array\n",
    "        sorted_m = np.argsort(m) # sorts from smallest to largest influence and returns index ordering\n",
    "        min_i, max_i = p_start*n, p_start*n + p_width*n # find min and max point given start and width\n",
    "        median_width = (1 - reduced_width)/2. # calculate the reduced width \n",
    "        min_i_median = round(min_i + (p_width*n*median_width))\n",
    "        max_i_median = round(max_i - (p_width*n*median_width))\n",
    "        \n",
    "        # use reduced width to select random example and return index\n",
    "        return random.choice(sorted_m[min_i_median:max_i_median]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to return the influence score of a given index\n",
    "def return_influence_of_index(scan_results, index):\n",
    "    influence_score = []\n",
    "    for model in scan_results:\n",
    "        influence_score.append(model[\"memorisation\"][index])\n",
    "    return influence_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're computing the influence scores from examples across different deciles and collecting results for all CP models into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1\n",
    "epoch_index = model_cps.index(EPOCH)\n",
    "m_selected = scan_results[epoch_index][\"memorisation\"] # influence scores from CP 50\n",
    "\n",
    "p_starts = np.linspace(0, 0.9, 10)\n",
    "\n",
    "indices = [] # store indices of examples\n",
    "for p_start in p_starts:\n",
    "    index = return_example_index(float(p_start), 0.1, 0.1, m_selected)\n",
    "    indices.append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the influence score for all the given indices. Generates a list of lists, where each list represent the evolution of a given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_10_examples = []\n",
    "for index in indices:\n",
    "    example_influence_across_CPs = []\n",
    "    for i, model in enumerate(model_cps):\n",
    "        if model == -1: \n",
    "            continue # skip averaged model\n",
    "        else:\n",
    "            infl_score = scan_results[i][\"memorisation\"][index]\n",
    "            example_influence_across_CPs.append(infl_score)\n",
    "    results_for_10_examples.append(example_influence_across_CPs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a plot of influence score vs different epochs for the 10 examples selected. This plot shows how influence score for a given example evolves over training. Note that the examples are selected from the 50th epoch and projected backwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 5), ncols=1)\n",
    "\n",
    "for i, value in enumerate(results_for_10_examples):\n",
    "    LABEL = \"{}\".format(i+1)                                           \n",
    "    ax.plot(model_cps[:-1], results_for_10_examples[i], \"-o\", markersize=5, label=LABEL, linewidth=2)\n",
    "\n",
    "ax.set_xlim([-1, 57])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='right', frameon=True, fontsize=10)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(\"Evolution of influence for individaul examples\", fontsize=14)\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Self Influence Score\", fontsize=12)\n",
    "\n",
    "plt.savefig(\"plots/self_influence_evolution_epoch_1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying the distributional evolution of influence in tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return upper X percentile indices\n",
    "def return_upper_percentile_indices(p, m):\n",
    "    \"\"\"\n",
    "    > This function returns the indices of the upper pth fraction of most influential examples\n",
    "    > p represents upper \"pth\" percentile of the dataset and is set between 0 and 1\n",
    "    \"\"\"\n",
    "    if p > 1:\n",
    "        \n",
    "        print (\"Set percentile between 0-1.\")\n",
    "    else:\n",
    "        n = len(m)\n",
    "        sorted_m = np.argsort(m)\n",
    "        min_i, max_i = round(n - p*n), n\n",
    "        return sorted_m[min_i:max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return upper X percentile indices\n",
    "def return_lower_percentile_indices(p, m):\n",
    "    \"\"\"\n",
    "    > This function returns the indices of the upper pth fraction of most influential examples\n",
    "    > p represents upper \"pth\" percentile of the dataset and is set between 0 and 1\n",
    "    \"\"\"\n",
    "    if p > 1:\n",
    "        print (\"Set percentile between 0-1.\")\n",
    "    else:\n",
    "        n = len(m)\n",
    "        sorted_m = np.argsort(m)\n",
    "        max_i = round(p*n)\n",
    "        return sorted_m[0:max_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of indices that match the selected models tail indices\n",
    "def return_match_index(scan_results, selected_model, p_width):\n",
    "    sub_list = return_upper_percentile_indices(p_width, selected_model[\"memorisation\"])\n",
    "    all_cp_index = []\n",
    "    for model in range(len(model_cps)):\n",
    "        index_list = [] # stores matching indices for model\n",
    "        sorted_model = np.argsort(scan_results[model][\"memorisation\"]) # sorting model in influence score\n",
    "        for item in sub_list:\n",
    "            index_list.append(np.where(sorted_model == item)[0][0])\n",
    "        all_cp_index.append(index_list)\n",
    "    return all_cp_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **return_match_index** to count the number of matches between the upper ***p_width*** highest influence examples of a selected epoch/model and all the other epochs/models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "epoch_index = model_cps.index(EPOCH)\n",
    "selected_model = scan_results[epoch_index]\n",
    "p_width=0.05 # selecting top 10%\n",
    "all_results = return_match_index(scan_results, selected_model, p_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformatting data structure to feed into **seaborn** plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data dictionary to feed into seaborn plot\n",
    "data = {\n",
    "    'CP 0' : all_results[0],\n",
    "    \"CP 1\" : all_results[1],\n",
    "    \"CP 2\" : all_results[2],\n",
    "    \"CP 3\" : all_results[3],\n",
    "    \"CP 4\" : all_results[4],\n",
    "    \"CP 5\" : all_results[5],\n",
    "    \"CP 10\" : all_results[6],\n",
    "    \"CP 20\" : all_results[7],\n",
    "    \"CP 30\" : all_results[8],\n",
    "    \"CP 40\" : all_results[9],\n",
    "    \"CP 50\" : all_results[10],\n",
    "    \"Ave. CP\" : all_results[11]\n",
    "}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.violinplot(ax=ax, data=df)\n",
    "plt.axhline(y=len(all_results[0])*(1/p_width-1), color='r', linestyle='-')\n",
    "plt.axvline(x=10.5, color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Ordered Self Influence Index\", fontsize=12)\n",
    "\n",
    "plt.savefig(\"plots/self_influence_distribution_evolution_epoch_1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pruned datasets\n",
    "This section is used to create and save pruned datasets. The indices are selected by removing a percentage of the most influential examples from the last epoch (50th). The indices are saved as lists into a pickle file to be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_indices_to_remove(data, epoch_index, prune_frac):\n",
    "    indices_to_remove = return_upper_percentile_indices(prune_frac, \n",
    "                                                  data[epoch_index][\"memorisation\"])[::-1].flatten()\n",
    "    return sorted(indices_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_indices_to_remove(data, epoch_index, prune_frac):\n",
    "    indices_to_remove = return_lower_percentile_indices(prune_frac, \n",
    "                                                  data[epoch_index][\"memorisation\"])[::-1].flatten()\n",
    "    return sorted(indices_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = -1\n",
    "epoch_index = model_cps.index(EPOCH)\n",
    "data = scan_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove upper\n",
    "prune_indices = []\n",
    "prune_frac_scan = [0.05, 0.010, 0.0125, 0.15, 0.175, 0.02, 0.0225, 0.025]\n",
    "for i, prune_frac in enumerate(prune_frac_scan):\n",
    "    prune_indices.append(upper_indices_to_remove(data, epoch_index, prune_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_datasets_dict = {\n",
    "    \"frac_list\" : prune_frac_scan,\n",
    "    \"prune_indices\" : prune_indices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save options\n",
    "EXTENSION = \"pruned_ds_cpave_bs500_2\".format(EPOCH)\n",
    "\n",
    "# store data (serialize)\n",
    "with open('results/{}.pickle'.format(EXTENSION), 'wb') as handle:\n",
    "    pickle.dump(pruned_datasets_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
