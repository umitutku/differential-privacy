{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 10\n",
    "\n",
    "This notebook trains a classifier on CIFAR10 using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import os.path\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 100 epochs will take ages on CPU, reduce or use GPU\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1000\n",
    "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(batch):\n",
    "    return (\n",
    "        {\n",
    "            \"image\": tf.cast(batch[\"image\"], tf.float32) / 255.,\n",
    "            \"id\": batch[\"id\"],\n",
    "        },\n",
    "        batch[\"label\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = tfds.load(\"cifar10\", split=[\"train\", \"test\"], data_dir=\"/tmp/tensorflow_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off a chunk of training data for validation\n",
    "val_ds = train_set.take(1000)\n",
    "train_set = train_set.skip(1000)\n",
    "\n",
    "train_ds = (\n",
    "    train_set\n",
    "    .shuffle(buffer_size=8 * BATCH_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(prepare)\n",
    ")\n",
    "val_ds = (\n",
    "    val_ds\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(prepare)\n",
    ")\n",
    "test_ds = (\n",
    "    test_set\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(prepare)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualise examples\n",
    "batch, labels = next(iter(train_ds))\n",
    "images = batch[\"image\"].numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, ncols=5, figsize=(12, 5))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.set_title(LABELS[labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining all test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(name=\"model\"):\n",
    "    block = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\", input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        \n",
    "        tf.keras.layers.Reshape((2048,)),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ], name=name)\n",
    "    \n",
    "    input_ = tf.keras.Input(name=\"image\", shape=(32, 32, 3))\n",
    "    output = block(input_)\n",
    "    model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        \"adam\",\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a checkpoint path to store model trainig history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checkpoint callback\n",
    "checkpoint_path = \"cp_training_cifar_10/cp-{epoch:04d}\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "BATCHES_PER_EPOCH = int(49000/BATCH_SIZE)\n",
    "\n",
    "# creating a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq=1*BATCHES_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating a CNN model on the cifar-10 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# save initialised model\n",
    "model.save(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(train_ds, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=val_ds,\n",
    "                    verbose=2,\n",
    "                    shuffle=False,\n",
    "                    callbacks=[cp_callback, tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=20)])\n",
    "end = time.time()\n",
    "print(\"Total time:\", datetime.timedelta(seconds=end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Summary of the model performance. The defined methods can be used to compare multiple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model plotter\n",
    "def plot_model_results(history, clr, i=\"_alt\"):\n",
    "    ax[0].plot(history.history[\"loss\"], \"{}\".format(clr), label=\"M{} Train loss\".format(i), linewidth=2)\n",
    "    ax[0].plot(history.history[\"val_loss\"], \"{}--\".format(clr), label=\"M{} Val loss\".format(i), linewidth=2)\n",
    "    ax[1].plot(history.history[\"sparse_categorical_accuracy\"], \"{}\".format(clr), label=\"M{} Train accuracy\".format(i), linewidth=1.5)\n",
    "    ax[1].plot(history.history[\"val_sparse_categorical_accuracy\"], \"{}--\".format(clr), label=\"M{} Val accuracy\".format(i), linewidth=1.5)\n",
    "    ax[0].set_xlabel(\"$Epochs$\", fontsize=16), ax[1].set_xlabel(\"$Epochs$\", fontsize=16)\n",
    "    ax[0].set_ylabel(\"$Loss$\", fontsize=16), ax[1].set_ylabel(\"$Accuracy$\", fontsize=16)\n",
    "    ax[0].set_title(\"Loss\", fontsize=18), ax[1].set_title(\"Accuracy\", fontsize=18)\n",
    "    ax[0].legend(frameon=False, fontsize=14), ax[1].legend(frameon=False, fontsize=14)\n",
    "    \n",
    "# print results\n",
    "def return_results(model, test_ds, i=\"0\"):\n",
    "    # Evaluate model comparison\n",
    "    test_batch, test_labels = next(iter(test_ds))\n",
    "    loss, acc = model.evaluate(test_batch, test_labels, verbose=0)\n",
    "    print(\"M{}|| Accuracy: {:.2f}% --- Loss: {:.2f}\".format(i, 100 * acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result summary \n",
    "return_results(model, test_ds)\n",
    "\n",
    "# create a loss & accuracy subplot\n",
    "f, ax = plt.subplots(figsize=(14, 6), ncols=2)\n",
    "\n",
    "# plot results of each model\n",
    "plot_model_results(history, \"g\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Influence \n",
    "#### Incorprating the self-influence code outlined in [TracIn paper](https://github.com/frederick0329/TracIn/blob/master/imagenet/resnet50_imagenet_self_influence.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method below calculations the self-influence (memorisation) score of a given training example for a given batch of images & labels and model checkpoints. Outputs from **run_self_influence** are concatenated into a dictionary using **memorisation_results** to simplify output. The indexing can be taken as the ID across each result member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# method to calculate self-influence of batch members.\n",
    "@tf.function\n",
    "def run_self_influence(images, labels, models):\n",
    "    self_influences = []\n",
    "    for m in models:\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "            tape.watch(m.trainable_weights)\n",
    "            probs = m(images, training=False)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(labels, probs, from_logits=True)\n",
    "        grads = tape.jacobian(loss, m.trainable_weights)\n",
    "        scores = tf.add_n([tf.math.reduce_sum(\n",
    "            grad * grad, axis=tf.range(1, tf.rank(grad), 1)) \n",
    "            for grad in grads])\n",
    "        self_influences.append(scores)  \n",
    "\n",
    "    # using probs from last checkpoint\n",
    "    probs, predicted_labels = tf.math.top_k(probs, k=1)\n",
    "    return tf.math.reduce_mean(tf.stack(self_influences, axis=-1), axis=-1), labels, probs, predicted_labels\n",
    "\n",
    "# method to concatenate all of the batch results together\n",
    "def memorisation_results(memorisation, images, probs, labels, predicted_labels):\n",
    "    result_dictionary = {\n",
    "        \"memorisation\": np.array(np.concatenate(memorisation)),\n",
    "        \"images\": np.concatenate(images),\n",
    "        \"probs\": np.concatenate(probs),\n",
    "        \"labels\": np.concatenate(labels),\n",
    "        \"predicted_labels\": np.concatenate(predicted_labels)\n",
    "    }\n",
    "    return result_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method incorprates **run_self_influence** and **memorisation_results** to return results for any given model scenario. It is used to study the comparisons between different CP memorisation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_self_influence(train_ds, models):\n",
    "    memorisation_list = []\n",
    "    image_list = []\n",
    "    probs_list = []\n",
    "    labels_list = [] \n",
    "    predicted_labels_list = []\n",
    "\n",
    "    start = time.time()\n",
    "    for batch, labels in train_ds:\n",
    "        memorisation_score, labels, probs, predictied_labels = run_self_influence(batch[\"image\"], labels, models)\n",
    "        memorisation_list.append(memorisation_score)\n",
    "        image_list.append(batch[\"image\"])\n",
    "        probs_list.append(probs)\n",
    "        labels_list.append(labels)\n",
    "        predicted_labels_list.append(predictied_labels)\n",
    "    end = time.time()\n",
    "    print(\"Total time:\", datetime.timedelta(seconds=end - start))\n",
    "    \n",
    "    return memorisation_results(memorisation_list, image_list, probs_list, labels_list, predicted_labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to load the desired model weights of a single or a list of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_models(epochs):\n",
    "    loaded_models = []\n",
    "    for epoch in epochs:\n",
    "        path = \"{}/cp_training_cifar_10/cp-00{:02d}\".format(os.getcwd(), epoch)\n",
    "        if os.path.exists(path) == False:\n",
    "            print (\"File not found: cp-00{:02d}\".format(epoch))\n",
    "        else:\n",
    "            model = tf.keras.models.load_model(\"cp_training_cifar_10/cp-00{:02d}\".format(epoch))\n",
    "            loaded_models.append(model)\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(train_ds, models):\n",
    "    results = [] \n",
    "    if len(models) > 1:\n",
    "        for model in models:\n",
    "            results.append(batch_self_influence(train_ds, [model]))\n",
    "    results.append(batch_self_influence(train_ds, models[1:])) # ave. self-influence\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models from different epochs to calculate CP memorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine training set with a reduced batch size for memory issues\n",
    "train_influence = (\n",
    "    train_set\n",
    "    .batch(50)\n",
    "    .map(prepare)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model index is later used to label plots\n",
    "model_cps = [0, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50]\n",
    "models = return_models(model_cps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all model results in a list \n",
    "#  > zeroth index holds averaged CP\n",
    "results = get_results(train_influence, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save options\n",
    "EXTENSION = \"scan_results_shuffled_1000\"\n",
    "\n",
    "# store data (serialize)\n",
    "with open('results/{}.pickle'.format(EXTENSION), 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
